{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/KaziFahmi/EDM_Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/EDM_Custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r /content/EDM_Custom/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import pathlib\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.warnings import PossibleUserWarning\n",
    "\n",
    "from midi.datasets import qm9_dataset, geom_dataset\n",
    "from midi.diffusion_model import FullDenoisingDiffusion\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import compose, initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd EDM_Custom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/\"  \n",
    "def load_hydra_configs(config_path):\n",
    "    with initialize(config_path=config_path):\n",
    "        cfg = compose(config_name=\"config\")\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xcdtl\\AppData\\Local\\Temp\\ipykernel_16228\\1311385683.py:3: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=config_path):\n"
     ]
    }
   ],
   "source": [
    "cfg = load_hydra_configs(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cfg:\n",
    "#     class dataset:\n",
    "#         name = 'qm9'\n",
    "#         datadir = 'train'\n",
    "#         base_path = '/'\n",
    "#         remove_h = True\n",
    "#         pin_memory = True\n",
    "#         random_subset = None\n",
    "#         adaptive_loader = True\n",
    "#     class train:\n",
    "#         n_epochs = 1000\n",
    "#         batch_size = 256\n",
    "#         reference_batch_size = 300\n",
    "#         lr = 0.0002\n",
    "#         clip_grad = None          # float, None to disable\n",
    "#         save_model = True\n",
    "#         num_workers = 0\n",
    "#         ema_decay = 0           # 'Amount of EMA decay, 0 means off. A reasonable value is 0.999.'\n",
    "#         progress_bar = None\n",
    "#         weight_decay = 1e-12\n",
    "#         scheduler = None\n",
    "#         seed = 0\n",
    "#     class model:\n",
    "#         # Model settings\n",
    "#         type = 'discrete'\n",
    "#         transition = 'marginal'                          # uniform or marginal\n",
    "#         model = 'graph_tf'\n",
    "#         diffusion_steps = 500\n",
    "#         diffusion_noise_schedule = 'cosine'              # 'cosine', 'polynomial_2'\n",
    "#         n_layers = 12\n",
    "#         extra_features = None        # 'all', 'cycles', 'eigenvalues' or None\n",
    "#         # Do not set hidden_mlp_E, dim_ffE too high, computing large tensors on the edges is costly\n",
    "#         # At the moment (03/08), y contains quite little information\n",
    "#         hidden_mlp_dims = {'X': 256, 'E': 64, 'y': 256, 'pos': 64}\n",
    "\n",
    "#         # The dimensions should satisfy dx % n_head == 0\n",
    "#         hidden_dims = {'dx': 256, 'de': 64, 'dy': 128, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 64, 'dim_ffy': 256}\n",
    "\n",
    "#         lambda_train = [3, 0.4, 1, 2, 0]\n",
    "#         nu = {'p': 2.5, 'x': 1, 'c': 1, 'e': 1.5, 'y': 1}\n",
    "#     class general:\n",
    "#         # General settings\n",
    "#         name = 'graph-tf-model'                   # Warning: 'debug' and 'test' are reserved name that have a special behavior\n",
    "#         wandb = 'online'                # online | offline | disabled\n",
    "#         gpus = 1                     # Multi-gpu is currently not implemented\n",
    "#         resume = None            # If resume, path to ckpt file from outputs directory in main directory\n",
    "#         test_only = None         # Use absolute path\n",
    "#         check_val_every_n_epochs = 5\n",
    "#         sample_every_val = 2\n",
    "#         val_check_interval = None\n",
    "#         samples_to_generate = 1024\n",
    "#         samples_to_save = 20\n",
    "#         chains_to_save= 1\n",
    "#         log_every_steps= 50\n",
    "#         number_chain_steps= 50        # Number of frames in each gif\n",
    "#         faster_sampling= 1                              # At each sampling step, set s=t-faster sampling (1 for normal sampling)\n",
    "#         final_model_samples_to_generate= 10000\n",
    "#         final_model_samples_to_save= 10\n",
    "#         final_model_chains_to_save: 5\n",
    "#         cpus_per_gpu= 4\n",
    "#         force_ray= False\n",
    "#         evaluate_all_checkpoints= False\n",
    "#         num_final_sampling= 5\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = cfg.dataset\n",
    "data_module = qm9_dataset.QM9DataModule(cfg)\n",
    "dataset_info = qm9_dataset.QM9infos(datamodule=data_module,cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen=OmegaConf.load('configs/general/general_default.yaml')\n",
    "\n",
    "# cfg.general = OmegaConf.merge(cfg,gen )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal distribution of the classes: nodes: tensor([0.7231, 0.1151, 0.1591, 0.0026]) -- edges: tensor([0.7261, 0.2383, 0.0274, 0.0082, 0.0000]) -- charges: tensor([0.0078, 0.9705, 0.0218])\n"
     ]
    }
   ],
   "source": [
    "model = FullDenoisingDiffusion(cfg=cfg, dataset_infos=dataset_info, train_smiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_ignore = ['module.model.train_smiles', 'module.model.dataset_infos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.parallel.DistributedDataParallel._set_params_and_buffers_to_ignore_for_model(model, params_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=f\"checkpoints/{cfg.general.name}\",\n",
    "                                              filename='{epoch}',\n",
    "                                              monitor='val/epoch_NLL',\n",
    "                                              save_top_k=5,\n",
    "                                              mode='min',\n",
    "                                              every_n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ckpt_save = ModelCheckpoint(dirpath=f\"checkpoints/{cfg.general.name}\", filename='last', every_n_epochs=1)\n",
    "callbacks.append(checkpoint_callback)\n",
    "callbacks.append(last_ckpt_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\xcdtl\\anaconda3\\envs\\midi\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(gradient_clip_val=cfg.train.clip_grad, # Needed to load old checkpoints\n",
    "                      accelerator='cpu',\n",
    "                      devices=cfg.general.gpus,\n",
    "                      max_epochs=cfg.train.n_epochs,\n",
    "                      check_val_every_n_epoch=cfg.general.check_val_every_n_epochs,\n",
    "                      fast_dev_run=cfg.general.name == 'debug',\n",
    "                      enable_progress_bar=cfg.train.progress_bar,\n",
    "                      callbacks=callbacks,\n",
    "                      log_every_n_steps=50,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILEPATH: /f:/FYDP/EDM_Custom/colab_notebook.ipynb\n",
    "trainer.fit(model, datamodule=data_module)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
